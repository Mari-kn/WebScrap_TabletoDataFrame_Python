{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c820f1b",
   "metadata": {
    "papermill": {
     "duration": 0.002487,
     "end_time": "2024-01-22T23:20:37.007785",
     "exception": false,
     "start_time": "2024-01-22T23:20:37.005298",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# In this code I scrap table in https://grg.org/Adams/C.HTM with BeautifulSoup library and push data in DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bcd795",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-01-22T23:20:37.014278Z",
     "iopub.status.busy": "2024-01-22T23:20:37.013628Z",
     "iopub.status.idle": "2024-01-22T23:20:55.166029Z",
     "shell.execute_reply": "2024-01-22T23:20:55.163126Z"
    },
    "papermill": {
     "duration": 18.158914,
     "end_time": "2024-01-22T23:20:55.168736",
     "exception": false,
     "start_time": "2024-01-22T23:20:37.009822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (4.12.2)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4) (2.3.2.post1)\r\n",
      "  Num    Birthplace                       Name           Born           Died  \\\n",
      "0   1  England (UK)                Betsy Baker  Aug. 20, 1842  Oct. 24, 1955   \n",
      "1   2  England (UK)              Jennie Howell  Feb. 11, 1845  Dec. 16, 1956   \n",
      "2   3       Denmark      Anne Marie Carstenson  Jan. 24, 1849  Mar. 30, 1958   \n",
      "3   4     U.S. (IN)                 Nancy Ryan  Sept. 5, 1849  Oct. 17, 1958   \n",
      "4   5   Netherlands  Christina Karnebeek-Backs  Oct.  2, 1849  Oct.  7, 1959   \n",
      "\n",
      "  Age_Years Age_Days Race Sex   Deathplace WhenOldest_Years_Range  \\\n",
      "0       113       65    W   F    U.S. (NE)                 ?-1955   \n",
      "1       111      309    W   F    U.S. (CA)              1955-1956   \n",
      "2       109       65    W   F    U.S. (NE)              1956-1958   \n",
      "3       109       42    W   F    U.S. (IN)                   1958   \n",
      "4       110        5    W   F  Netherlands              1958-1959   \n",
      "\n",
      "  WhenOldestAge_Range Lenght_of_Region_Years Lenght_of_Region_Days  \\\n",
      "0               ?-113                   N.A.                  N.A.   \n",
      "1             110-111                      1                    53   \n",
      "2             107-109                      1                   104   \n",
      "3             108-109                      0                   201   \n",
      "4             109-110                      0                   355   \n",
      "\n",
      "  Region_Lenghts_inYear Age_at_Accession_Years Age_at_Accession_Days  \\\n",
      "0                  N.A.                   N.A.                  N.A.   \n",
      "1                  1.14                    110                   255   \n",
      "2                  1.28                    107                   327   \n",
      "3                  0.55                    108                   206   \n",
      "4                  0.97                    109                    15   \n",
      "\n",
      "  Case added to GRG Tablee  \n",
      "0                     N.A.  \n",
      "1            Aug. 29, 2017  \n",
      "2     N.A. (less than 110)  \n",
      "3     N.A. (less than 110)  \n",
      "4       original 1999 list  \n"
     ]
    }
   ],
   "source": [
    "# Install the BeautifulSoup4 library if not already installed\n",
    "!pip install beautifulsoup4\n",
    "\n",
    "# Import necessary libraries\n",
    "from bs4 import BeautifulSoup  # For parsing HTML and XML documents\n",
    "from urllib.request import urlopen  # To fetch data from a URL\n",
    "import pandas as pd  # For data manipulation and analysis\n",
    "\n",
    "# Define the URL of the target web page\n",
    "url_base = 'https://grg.org/Adams/C_files/sheet001.htm'\n",
    "\n",
    "# Open the URL and read its content\n",
    "u = urlopen(url_base)\n",
    "html = u.read()  # Read the HTML content of the page\n",
    "\n",
    "# Try decoding the HTML content using 'utf-8', handle potential decoding errors\n",
    "try:\n",
    "    decoded_html = html.decode('utf-8')\n",
    "except UnicodeDecodeError:\n",
    "    # If decoding with 'utf-8' fails, fall back to 'latin-1' encoding and replace problematic characters\n",
    "    decoded_html = html.decode('latin-1', errors='replace')\n",
    "\n",
    "# Close the URL connection\n",
    "u.close()\n",
    "\n",
    "# Parse the decoded HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(decoded_html, 'html.parser')\n",
    "\n",
    "# Find the first table element in the HTML document\n",
    "Table = soup.find(\"table\")\n",
    "\n",
    "# Optional: Uncomment to print a prettified version of the table's HTML\n",
    "# print(Table.prettify)\n",
    "\n",
    "# Define column names for the DataFrame\n",
    "columns = [\"Num\", \"Birthplace\", \"Name\", \"Born\", \"Died\", \"Age_Years\", \"Age_Days\", \"Race\", \"Sex\", \n",
    "           \"Deathplace\", \"WhenOldest_Years_Range\", \"WhenOldestAge_Range\", \"Lenght_of_Region_Years\", \n",
    "           \"Lenght_of_Region_Days\", \"Region_Lenghts_inYear\", \"Age_at_Accession_Years\", \n",
    "           \"Age_at_Accession_Days\", \"Case added to GRG Tablee\", \"C1\", \"C2\", \"C3\", \"C4\"]\n",
    "\n",
    "# Initialize an empty list to store table data\n",
    "data = []\n",
    "\n",
    "# Loop through specific rows in the table (from row 8 to row 72, inclusive) to extract data\n",
    "for row in Table.find_all('tr')[8:73]:\n",
    "    # Extract text from each table cell, strip whitespace, and append to row_data\n",
    "    row_data = [cell.text.strip() for cell in row.find_all('td')]\n",
    "    data.append(row_data)  # Add the row data to the data list\n",
    "\n",
    "# Create a DataFrame using the extracted data and specified column names\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "# Optional: Uncomment to preview the first 10 rows of the DataFrame\n",
    "# print(df.head(10))\n",
    "\n",
    "# Slice the DataFrame to keep only the first 18 columns\n",
    "df = df.iloc[:, :18]\n",
    "\n",
    "# Print the first 5 rows of the DataFrame to verify the output\n",
    "print(df.head(5))\n",
    "\n",
    "# Save the DataFrame to a CSV file named 'webscrape.csv'\n",
    "df.to_csv('webscrape.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30635,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 22.75234,
   "end_time": "2024-01-22T23:20:55.996065",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-01-22T23:20:33.243725",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
